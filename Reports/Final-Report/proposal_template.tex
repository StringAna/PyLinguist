%
% File proposal_template.tex
%
%% Based on the style files for ACL 2018, NAACL 2018/19, which were
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,
%% EACL-2009, IJCNLP-2008...
%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{acl2019}
\usepackage{times}
\usepackage{latexsym}
\usepackage{enumitem}
\usepackage{url}

\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\newcommand\BibTeX{B\textsc{ib}\TeX}

\title{PyLinguist: Automated Translation of Python for Hindi Programmers}

\author{First Author \\
  Antara Tewary\\ 
  G01413546\\
  \texttt{atewary@gmu.edu} \\\And
  Second Author \\
  Ankit Kumar\\ 
  G01436204\\
  \texttt{akumar37@gmu.edu}\\\And
  Third Author \\
  Homa Haghighi\\ 
  G01436204\\
  \texttt{akumar37@gmu.edu}}

\date{December 6,2024}

\begin{document}
\maketitle

\section{Introduction}
Python is a popular programming language, which has gained its popularity due to many factors, which include its readability and intuitive English-like syntax that makes the code accessible to English speakers. However, this can be a significant barrier for non-English speakers who have to grapple with both the programming concepts and learning a new language. Our project addresses this issue by developing a comprehensive translation system that converts Python code from English to Hindi, making Python programming more accessible to Hindi speakers while maintaining code functionality and readability.
            \subsection{Task / Research Question Description} 
            Core research questions are-\\
            - How can we effectively translate Python's syntax, keywords, and natural language elements while preserving code functionality?\\
            - What combination of translation techniques provides optimal results for code translation??\\
            - How can we quantitatively and qualitatively evaluate the effectiveness of code translation?\\ \\
            Our project implements a three-stage translation pipeline combining keyword dictionaries, Google Translate API, and GPT models, with comprehensive evaluation metrics to assess translation quality and code functionality preservation.
            \subsection{Motivation \& Limitations of existing work} 
            While Python's pseudo-code nature simplifies programming for English speakers, it presents significant challenges for non-English speakers who comprise the majority of the global population. Research has shown that students learn programming concepts more effectively when using a coding language based on their native language. Current solutions like CodeInternational partially address this issue by translating comments and identifiers, but they fall short of providing a complete solution that encompasses Python's built-in functions, keywords, and error messages.\\ \\ 
            Limitations of existing work include:
            \begin{itemize}[itemsep=0pt, topsep=0pt]
                \item Incomplete coverage of Python's language elements
                \item Lack of consistency in technical term translation
                \item Limited handling of language-specific challenges
                \item Insufficient preservation of code functionality
                \item Absence of comprehensive evaluation metrics
            \end{itemize} 
            \subsection{Proposed Approach} 
            Our solution implements a three-stage pipeline that combines rule-based translation, neural machine translation and large language model enhancements:
            \begin{itemize}[itemsep=0pt, topsep=0pt]
                \item \textbf{Stage 0: Data Preprocessing}\\ 
                Initial stage aimed to prepare high-quality Python code data for training and evaluation purposes. We used the "python-code-dataset-500k" dataset from hugging face \cite{jtatman2021python} which provides a diverse collection of Python code exmaples. This stage involves-\\ \\ 
                - Downloading and cleaning the dataset\\ 
                - Extracting Python code that was enclosed in the \texttt{<pythoncode>} tags using regex\\ 
                - Storing the cleaned code in a structured CSV format with \texttt{English\_code} column.
                \item \textbf{Stage 1: Initial Translation}\\
                The first translation stage combines keyword mapping with neural machine translation:
                \begin{itemize}[itemsep=0pt, topsep=0pt]
                    \item Used curated keyword dictionary created by Joshua Otten \cite{otten2021unipy} which 223 keywords in python and their Hindi translations.
                    \item Direct translation of keywords using this dictionary
                    \item Then, we apply Google Translate API for translating the comments, strings and natural language elements.
                    \item Special handling of compound variables with underscores by splitting, translating split components individually, and rejoining them.
                    \item This gives us an initial Hindi code version with basic translations.
                \end{itemize}
                \item \textbf{Stage 2: GPT Enhancement}\\
                The second stage leverages GPT-4o Mini to refine and improve translations through example-based learning:
                \begin{itemize}[itemsep=0pt, topsep=0pt]
                    \item Using the Hindi code generated in Stage 1 output as reference examples for the model
                    \item Creating a customized prompt that shows the desired translation patterns to GPT model
                    \item We provide both the English code and the partially translated Hindi code from Stage 1
                    \item We use GPT to enhance the translation while preserving code functionality and structure
                    \item This generates a more natural and contexually appropriate Hindi version 
                \end{itemize}
            \end{itemize}
            \subsection{Likely challenges and mitigations} 
            There are several challenges in trying to translate Python code between English and Hindi. Our implementation tackles these through specific mitigation strategies:-
            \begin{itemize}[itemsep=0pt, topsep=0pt]
              \item \textbf{Compound Word Translation}: Code often contains compound words separated by underscores. The \texttt{translate\_token} method in the \texttt{CodeTranslator} class handles this by splitting compound words, translating individual components, and rejoining them with underscores to maintain code readability.
              \item \textbf{Code Structure Preservation}: Maintaining code formatting and structure is crucial for readability and execution. The \texttt{translate\_line} method preserves indentation and line structure by measuring leading whitespace before translation and restoring it afterward.
              \item \textbf{Translation Reliability}: To handle potential translation failures, we apply two important features in our code. The \texttt{safe\_translate} method, which includes a retry mechanism for failed translations. Next is the \texttt{CheckpointManager} class which maintains translation progress. This allows longer translation tasks to be resumed if they are interrupted.
              \item \textbf{Keyword Translation}: Python keywords and built-in functions need consistent translation. The \texttt{KeywordManager} class maintains a dictionary mapping between English and Hindi keywords, which use Joshua Otten's curated dataset \cite{otten2021unipy}.
              \item \textbf{Comments and String Handling}: Code comments need a different handling than executable code. The \texttt{translate\_line} method identifies comments by looking at the \texttt{'\#'} character and applying separate translation rules for code and comment sections. This preserves the comments. 
            \end{itemize}
            These challenges are addressed through specific implementation, though future work can definitely improve these solutions.

\section{Related Work}


\section{Experiments}

\subsection{Datasets}
Please list which datasets you used, whether or not you have access them, and whether or not they are publicly available with the same preprocessing and train / dev / tests as the previous work you will be comparing to (if applicable). If you plan to collect your own dataset for evaluating robustness, please describe clearly the data plan (the data source, how you plan to collect it, how you would preprocess it for the task, etc.).

\subsection{Implementation} 
Please provide a link to a repo of your reimplementation (if applicable) and appropriately cite any resources you have used.

\section{Evaluation}
\subsection{Dataset and Test Configuration}
\begin{itemize}[itemsep=0pt, topsep=0pt]
    \item \textbf{Total Dataset}: 500k Python code samples from hugging face \cite{jtatman2021python}
    \item \textbf{Test Configuration}:\\ 
    - Translation set: 10 samples selected for translation\\
    - Example sets: Varying sizes (5,10,20,30) that are given to GPT model for reference\\ 
    - Human evaluation set: 20 samples evaluated by human evaluators
    \item \textbf{Keyword Dictionary}: 234 pre-mapped English-Hindi keyword pairs translated by Joshua Otten.
\end{itemize}
\subsection{Human Evaluation Framework}
Two bilingual evaluators (Hindi-English) with 4 years of experience in Python programming evaluated 20 code samples generated by our model. They followed the following rating scale-\\ 
\textit{\underline{Rating Scale(1-5)}}:
\begin{itemize}[itemsep=0pt, topsep=0pt]
    \item \textbf{1}: Unusable and incorrect translation
    \item \textbf{2}: Partially correct translation, major revisions needed
    \item \textbf{3}: Mostly correct translation, minor revisions needed
    \item \textbf{4}: Good translations with minimal revisions needed
    \item \textbf{5}: Perfect translation, no revisions needed
\end{itemize}
\textit{\underline{Evaluation Criteria}}:
\begin{itemize}[itemsep=0pt, topsep=0pt]
    \item \textbf{Syntax Correctness (SC)}: Proper keyword translation, code structure preservation and indentation accuracy
    \item \textbf{Semantic Preservation (SP)}: Logic preservation, variable scope maintenance and function behavior consistency
    \item \textbf{Hindi Language Quality (HLQ)}: Evaluating natural hindi expressions, the technical term consistency, comment clarity and code readability
\end{itemize}
\subsection{Technical Evaluation Framework}
\textit{\underline{Syntax Validation}}
\begin{itemize}[itemsep=0pt, topsep=0pt]
    \item \textbf{AST(Abstract Syntax Tree) Validation}: Tests if translated code produces valid Python AST and gives a binary outcome of Valid/Invalid\\
    - Result: ????
    \item \textbf{Token Structure Analysis}: Compares token types between original and translated code, uses Python's tokenize module\\
    Similarity score: 0.6250 ????
\end{itemize}
\textit{\underline{Semantic Testing}}\\We use the \texttt{SemanticTester} class to text the following:
\begin{itemize}[itemsep=0pt, topsep=0pt]
    \item \textbf{Execution Equivalence}:Runs both original and translated code, compares outputs for identical inputs\\
    - Success rate: 0.5999 across test cases ????
    \item \textbf{Runtime Behavior}: Tests error handling, verifies output types and memory usage patterns
\end{itemize}
\textit{\underline{Translation Quality Metrics}}
\begin{itemize}
  \item \textbf{BLEU Score Evaluation}:INSERT GRAPH HERE and Explain
  \item \textbf{Back Translation Validation}:INSERT GRAPH HERE and Explain
\end{itemize}
\section{Results}
Provide a table comparing your results to the published results.

\subsection{Discussion}
Discuss any issues you faced. Do your results differ from the published ones? If yes, why do you think that is? Did you do a sensitivity analysis (e.g. multiple runs with different random seeds)?

\subsection{Resources}
Discuss the cost of your reproduction in terms of resources: computation, time, people, development effort, communication with the authors (if applicable).


\subsection{Error Analysis}
Perform an error analysis on the model. Include at least 2-3 instances where the model fails. Discuss the error analysis in the paper -- what other analyses could the authors have ran? If you were able to perform additional error analyses, report it here.

\section{Robustness Study}
Explain your approach for Evaluating the Model Robustness. Describe what robustness analysis you have performed. Provide sufficient details about your perturbation data, how you created it, how you used it as a robustness benchmark to evaluate the model, in what metrics, etc.

\subsection{Results of Robustness Evaluation}
Describe the evaluation results of your reproduced model on the robustness benchmark that you created. Include at least 2 examples where the model performs well and 2 examples where it fails (i.e., being not robust). Provide sufficient analysis and your thoughts on the observations.

\subsection{Discussion} 
Provide any further discussion here, e.g., what challenges did you face when performing the analysis, and what could have been done if you will have more time on this project? Imagine you are writing this report to future researchers; be sure to include "generalizable insights" (e.g., broadly speaking, any tips or advice you'd like to share for researchers trying to analyze the robustness of an NLP model).

\section{Workload Clarification}
Describe how  the team divides the workload in this checkpoint. Note that each team member should contribute roughly the same amount of work to this assignment.

\section{Conclusion}
Is the paper reproducible?

% \section{Credits}

% This document has been adapted from the instructions
% for earlier ACL and NAACL proceedings,
% including 
% those for 
% NAACL 2019 by Stephanie Lukin and Alla Roskovskaya, 
% ACL 2018 by Shay Cohen, Kevin Gimpel, and Wei Lu, 
% NAACL 2018 by Margaret Michell and Stephanie Lukin,
% 2017/2018 (NA)ACL bibtex suggestions from Jason Eisner,
% ACL 2017 by Dan Gildea and Min-Yen Kan, 
% NAACL 2017 by Margaret Mitchell, 
% ACL 2012 by Maggie Li and Michael White, 
% those from ACL 2010 by Jing-Shing Chang and Philipp Koehn, 
% those for ACL 2008 by JohannaD. Moore, Simone Teufel, James Allan, and Sadaoki Furui, 
% those for ACL 2005 by Hwee Tou Ng and Kemal Oflazer, 
% those for ACL 2002 by Eugene Charniak and Dekang Lin, 
% and earlier ACL and EACL formats.
% Those versions were written by several
% people, including John Chen, Henry S. Thompson and Donald
% Walker. Additional elements were taken from the formatting
% instructions of the \emph{International Joint Conference on Artificial
%   Intelligence} and the \emph{Conference on Computer Vision and
%   Pattern Recognition}.

\bibliographystyle{acl_natbib} % We choose the "plain" reference style
\bibliography{refs} % Entries are in the refs.bib file

\end{document}
