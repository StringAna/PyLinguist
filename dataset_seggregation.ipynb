{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "\n",
    "# ds = load_dataset(\"jtatman/python-code-dataset-500k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds['train'].to_pandas()['output'].to_csv('data/dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Here is an example of a nested loop in Python ...\n",
       "1    The given problem can be solved by iterating t...\n",
       "2    Here's an example of code that attempts to sol...\n",
       "3    Here is an implementation of the function in P...\n",
       "4    Here's a possible implementation of the method...\n",
       "Name: output, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['output'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract Python code blocks from text\n",
    "def extract_python_code_blocks(text):\n",
    "    # Regular expression pattern to match text between ```python and ```\n",
    "    pattern = r'```python(.*?)```'\n",
    "    \n",
    "    # Find all matches in the text\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    \n",
    "    # Return the extracted code blocks\n",
    "    return [match.strip() for match in matches]\n",
    "\n",
    "# Convert the list of strings into a DataFrame\n",
    "df = pd.DataFrame(dataset, columns=['output'])\n",
    "\n",
    "# Extract Python code blocks from each element in the DataFrame\n",
    "df['extracted_code'] = df['output'].apply(extract_python_code_blocks)\n",
    "\n",
    "# Flatten the list of extracted code blocks and create a new DataFrame\n",
    "flattened_code_blocks = [code for sublist in df['extracted_code'] for code in sublist]\n",
    "code_df = pd.DataFrame(flattened_code_blocks, columns=['English_code'])\n",
    "\n",
    "# Save the extracted code blocks into a CSV file\n",
    "code_df.to_csv('data/extracted_code_blocks.csv', index=False)\n",
    "\n",
    "# Print the DataFrame to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to translate Python code from English to Hindi\n",
    "def translate_code_to_hindi(code):\n",
    "    \"\"\"\n",
    "    Translates Python code from English to Hindi while preserving code structure.\n",
    "    \"\"\"\n",
    "    translator = Translator()\n",
    "    \n",
    "    # Dictionary for common Python keywords translation\n",
    "    python_keywords = {\n",
    "        'for': 'के लिए',\n",
    "        'in': 'में',\n",
    "        'range': 'रेंज',\n",
    "        'if': 'अगर',\n",
    "        'and': 'और',\n",
    "        'print': 'छपिये',\n",
    "        'def': 'परिभाषा',\n",
    "        'return': 'वापसी',\n",
    "        'while': 'जबकि',\n",
    "        'else': 'अन्यथा',\n",
    "        'elif': 'या_फिर',\n",
    "        'True': 'सही',\n",
    "        'False': 'गलत',\n",
    "        'None': 'कुछ_नहीं',\n",
    "        'import': 'आयात',\n",
    "        'class': 'वर्ग',\n",
    "        'try': 'कोशिश',\n",
    "        'except': 'सिवाय',\n",
    "        'finally': 'अंत_में',\n",
    "        'with': 'साथ',\n",
    "        'as': 'के_रूप_में',\n",
    "        'from': 'से',\n",
    "        'break': 'तोड़ो',\n",
    "        'continue': 'जारी',\n",
    "        'pass': 'पास'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Split code into lines\n",
    "        lines = code.split('\\n')\n",
    "        translated_lines = []\n",
    "        \n",
    "        for line in lines:\n",
    "            # Check if line contains a comment\n",
    "            if '#' in line:\n",
    "                code_part, comment_part = line.split('#', 1)\n",
    "                \n",
    "                # Translate the comment\n",
    "                translated_comment = translator.translate(comment_part.strip(), src='en', dest='hi').text\n",
    "                \n",
    "                # Translate variable names in code part\n",
    "                for eng_word, hindi_word in python_keywords.items():\n",
    "                    code_part = code_part.replace(eng_word + ' ', hindi_word + ' ')\n",
    "                \n",
    "                # Combine translated parts\n",
    "                translated_line = f\"{code_part}# {translated_comment}\"\n",
    "            \n",
    "            else:\n",
    "                # Translate only code parts if no comment exists\n",
    "                translated_line = line\n",
    "                for eng_word, hindi_word in python_keywords.items():\n",
    "                    translated_line = translated_line.replace(eng_word + ' ', hindi_word + ' ')\n",
    "            \n",
    "            translated_lines.append(translated_line)\n",
    "        \n",
    "        return '\\n'.join(translated_lines)\n",
    "    except Exception as e:\n",
    "        return f\"Translation Error: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i in range(10):  # First digit\\n    for j in range(10):  # Second digit\\n        for k in range(10):  # Third digit\\n            # Checking for the conditions\\n            if i != 5 and j != 5 and k != 5 and i != j and i != k and j != k:\\n                print(i, j, k)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_df['English_code'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>for i in range(10):  # First digit\\n    for j ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>def count_distinct_states(matrix):\\n    count ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>def remove_spaces_and_punctuation(s):\\n    res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>def remove_spaces_and_punctuation(s):\\n    res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>import math\\n\\ndef is_prime(n):\\n    # Check i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        English_code\n",
       "0  for i in range(10):  # First digit\\n    for j ...\n",
       "1  def count_distinct_states(matrix):\\n    count ...\n",
       "2  def remove_spaces_and_punctuation(s):\\n    res...\n",
       "3  def remove_spaces_and_punctuation(s):\\n    res...\n",
       "4  import math\\n\\ndef is_prime(n):\\n    # Check i..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.set_option('display.max_colwidth', None)\n",
    "code_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translating the keywords and making the dataset for the Hindi version of the code using google translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m translator \u001b[38;5;241m=\u001b[39m Translator()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Translate the code from English to Hindi\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m code_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHindi_code\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mcode_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEnglish_code\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranslator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhi\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Save the translated code blocks into a CSV file\u001b[39;00m\n\u001b[1;32m     17\u001b[0m code_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/translated_code_blocks.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/NLP/lib/python3.12/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/NLP/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/NLP/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/envs/NLP/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/NLP/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[13], line 14\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     11\u001b[0m translator \u001b[38;5;241m=\u001b[39m Translator()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Translate the code from English to Hindi\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m code_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHindi_code\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m code_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnglish_code\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mtranslator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhi\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Save the translated code blocks into a CSV file\u001b[39;00m\n\u001b[1;32m     17\u001b[0m code_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/translated_code_blocks.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/NLP/lib/python3.12/site-packages/googletrans/client.py:182\u001b[0m, in \u001b[0;36mTranslator.translate\u001b[0;34m(self, text, dest, src, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    181\u001b[0m origin \u001b[38;5;241m=\u001b[39m text\n\u001b[0;32m--> 182\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_translate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# this code will be updated when the format is changed.\u001b[39;00m\n\u001b[1;32m    185\u001b[0m translated \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([d[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m d[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data[\u001b[38;5;241m0\u001b[39m]])\n",
      "File \u001b[0;32m~/anaconda3/envs/NLP/lib/python3.12/site-packages/googletrans/client.py:78\u001b[0m, in \u001b[0;36mTranslator._translate\u001b[0;34m(self, text, dest, src, override)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_translate\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, dest, src, override):\n\u001b[0;32m---> 78\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_acquirer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     params \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mbuild_params(query\u001b[38;5;241m=\u001b[39mtext, src\u001b[38;5;241m=\u001b[39msrc, dest\u001b[38;5;241m=\u001b[39mdest,\n\u001b[1;32m     80\u001b[0m                                 token\u001b[38;5;241m=\u001b[39mtoken, override\u001b[38;5;241m=\u001b[39moverride)\n\u001b[1;32m     82\u001b[0m     url \u001b[38;5;241m=\u001b[39m urls\u001b[38;5;241m.\u001b[39mTRANSLATE\u001b[38;5;241m.\u001b[39mformat(host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pick_service_url())\n",
      "File \u001b[0;32m~/anaconda3/envs/NLP/lib/python3.12/site-packages/googletrans/gtoken.py:194\u001b[0m, in \u001b[0;36mTokenAcquirer.do\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m     tk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macquire(text)\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tk\n",
      "File \u001b[0;32m~/anaconda3/envs/NLP/lib/python3.12/site-packages/googletrans/gtoken.py:62\u001b[0m, in \u001b[0;36mTokenAcquirer._update\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# this will be the same as python code after stripping out a reserved word 'var'\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRE_TKK\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvar \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# unescape special ascii characters such like a \\x3d(=)\u001b[39;00m\n\u001b[1;32m     64\u001b[0m code \u001b[38;5;241m=\u001b[39m code\u001b[38;5;241m.\u001b[39mencode()\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124municode-escape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "# I've rows with the python code and the output and the comments added in it. I want to translate the code from english to Hindi using googletrans library.\n",
    "# here is the example for the code \n",
    "# 'for i in range(10):  # First digit\\n    for j in range(10):  # Second digit\\n        for k in range(10):  # Third digit\\n            # Checking for the conditions\\n            if i != 5 and j != 5 and k != 5 and i != j and i != k and j != k:\\n                print(i, j, k)'\n",
    "# I will use googletrans library to translate the code from english to Hindi and for the comment I'll translate until it encounter the '\\n' .\n",
    "# 'के ई में रेंज(10):  # पहला अंक\\n    के जे में रेंज(10):  # दूसरा अंक\\n        के के में रेंज(10):  # तीसरा अंक\\n            # शर्तों की जांच करना\\n            अगर ई != 5 और जे != 5 और के != 5 और ई != जे और ई != के और जे != के:\\n                छपिये (ई, जे, के)'\n",
    "# I'll use the googletrans library to translate the code from english to Hindi and for the comment I'll translate until it encounter the '\\n' .\n",
    "\n",
    "from googletrans import Translator\n",
    "\n",
    "# Create a translator object\n",
    "translator = Translator()\n",
    "\n",
    "# Translate the code from English to Hindi\n",
    "code_df['Hindi_code'] = code_df['English_code'].apply(lambda x: translator.translate(x, src='en', dest='hi').text)\n",
    "\n",
    "# Save the translated code blocks into a CSV file\n",
    "code_df.to_csv('data/translated_code_blocks.csv', index=False)\n",
    "\n",
    "# Print the DataFrame to verify\n",
    "code_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting translation process...\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "from googletrans import Translator\n",
    "\n",
    "# Function to translate Python code from English to Hindi\n",
    "def translate_code_to_hindi(code):\n",
    "    \"\"\"\n",
    "    Translates Python code from English to Hindi while preserving code structure.\n",
    "    \"\"\"\n",
    "    translator = Translator()\n",
    "    \n",
    "    # Dictionary for common Python keywords translation\n",
    "    python_keywords = {\n",
    "        'for': 'के लिए',\n",
    "        'in': 'में',\n",
    "        'range': 'रेंज',\n",
    "        'if': 'अगर',\n",
    "        'and': 'और',\n",
    "        'print': 'छपिये',\n",
    "        'def': 'परिभाषा',\n",
    "        'return': 'वापसी',\n",
    "        'while': 'जबकि',\n",
    "        'else': 'अन्यथा',\n",
    "        'elif': 'या_फिर',\n",
    "        'True': 'सही',\n",
    "        'False': 'गलत',\n",
    "        'None': 'कुछ_नहीं',\n",
    "        'import': 'आयात',\n",
    "        'class': 'वर्ग',\n",
    "        'try': 'कोशिश',\n",
    "        'except': 'सिवाय',\n",
    "        'finally': 'अंत_में',\n",
    "        'with': 'साथ',\n",
    "        'as': 'के_रूप_में',\n",
    "        'from': 'से',\n",
    "        'break': 'तोड़ो',\n",
    "        'continue': 'जारी',\n",
    "        'pass': 'पास'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Split code into lines\n",
    "        lines = code.split('\\n')\n",
    "        translated_lines = []\n",
    "        \n",
    "        for line in lines:\n",
    "            # Check if line contains a comment\n",
    "            if '#' in line:\n",
    "                code_part, comment_part = line.split('#', 1)\n",
    "                \n",
    "                # Translate the comment\n",
    "                translated_comment = translator.translate(comment_part.strip(), src='en', dest='hi').text\n",
    "                \n",
    "                # Translate variable names in code part\n",
    "                for eng_word, hindi_word in python_keywords.items():\n",
    "                    code_part = code_part.replace(eng_word + ' ', hindi_word + ' ')\n",
    "                \n",
    "                # Combine translated parts\n",
    "                translated_line = f\"{code_part}# {translated_comment}\"\n",
    "            \n",
    "            else:\n",
    "                # Translate only code parts if no comment exists\n",
    "                translated_line = line\n",
    "                for eng_word, hindi_word in python_keywords.items():\n",
    "                    translated_line = translated_line.replace(eng_word + ' ', hindi_word + ' ')\n",
    "            \n",
    "            translated_lines.append(translated_line)\n",
    "        \n",
    "        return '\\n'.join(translated_lines)\n",
    "    except Exception as e:\n",
    "        return f\"Translation Error: {str(e)}\"\n",
    "\n",
    "# Function to extract Python code blocks from text\n",
    "def extract_python_code_blocks(text):\n",
    "    # Regular expression pattern to match text between ```python and ```\n",
    "    pattern = r'```python(.*?)```'\n",
    "    \n",
    "    # Find all matches in the text\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    \n",
    "    # Return the extracted code blocks\n",
    "    return [match.strip() for match in matches]\n",
    "\n",
    "def main():\n",
    "    # Create data directory if it doesn't exist\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    \n",
    "    # Load or create dataset\n",
    "    if not os.path.exists('data/dataset.csv'):\n",
    "        ds = load_dataset(\"jtatman/python-code-dataset-500k\")\n",
    "        ds['train'].to_pandas()['output'].to_csv('data/dataset.csv', index=False)\n",
    "    \n",
    "    # Read the dataset\n",
    "    dataset = pd.read_csv('data/dataset.csv')\n",
    "    \n",
    "    # Convert the list of strings into a DataFrame\n",
    "    df = pd.DataFrame(dataset, columns=['output'])\n",
    "    \n",
    "    # Extract Python code blocks from each element in the DataFrame\n",
    "    df['extracted_code'] = df['output'].apply(extract_python_code_blocks)\n",
    "    \n",
    "    # Flatten the list of extracted code blocks and create a new DataFrame\n",
    "    flattened_code_blocks = [code for sublist in df['extracted_code'] for code in sublist]\n",
    "    code_df = pd.DataFrame(flattened_code_blocks, columns=['English_code'])\n",
    "    \n",
    "    # Save the extracted code blocks\n",
    "    code_df.to_csv('data/extracted_code_blocks.csv', index=False)\n",
    "    \n",
    "    # Translate code to Hindi using our custom function\n",
    "    print(\"Starting translation process...\")\n",
    "    code_df['Hindi_code'] = code_df['English_code'].apply(translate_code_to_hindi)\n",
    "    \n",
    "    # Save the translated code blocks\n",
    "    code_df.to_csv('data/translated_code_blocks.csv', index=False)\n",
    "    \n",
    "    # Display some examples\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    print(\"\\nFirst few translations:\")\n",
    "    print(code_df.head())\n",
    "    \n",
    "    return code_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        code_df = main()\n",
    "        print(\"\\nTranslation completed successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
